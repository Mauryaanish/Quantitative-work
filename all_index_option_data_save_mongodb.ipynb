{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7dc1cdf-df7d-4e95-9dd6-227c44de7e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import subprocess\n",
    "import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.optimize import brentq\n",
    "from scipy.stats import norm\n",
    "from math import exp, log, sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4102a6-5d9b-4a07-87cd-f2b265e0fa87",
   "metadata": {},
   "source": [
    "# Find Expiry path all index expirys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff3a758e-ccbc-43ec-8739-f1e6dd918d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_expiry_path(today_date_str):\n",
    "    month = datetime.today().month\n",
    "    year = datetime.today().year\n",
    "    data_path = f'Y:\\\\daily_contract_file\\\\{today_date_str}\\\\*'\n",
    "    \n",
    "    # Read file paths into a DataFrame\n",
    "    file_paths = pd.DataFrame(glob(data_path), columns=['path'])\n",
    "    \n",
    "    # Extract split_data, index_name, and expiry using a single apply\n",
    "    file_paths['split_data'] = file_paths['path'].apply(lambda x: x.split('\\\\')[-1])\n",
    "    file_paths[['index_name', 'expiry']] = file_paths['split_data'].str.extract(r'([^_]+)_(\\d{8})')\n",
    "    \n",
    "    # Remove rows where expiry is 'index'\n",
    "    file_paths = file_paths[file_paths['expiry'] != 'index']\n",
    "    \n",
    "    # Convert 'expiry' to datetime and sort the DataFrame\n",
    "    file_paths['expiry'] = pd.to_datetime(file_paths['expiry'], format='%d%m%Y')\n",
    "    file_paths = file_paths.sort_values(by='expiry')\n",
    "    \n",
    "    # Create separate DataFrames for each index_name\n",
    "    index_names = ['BANKNIFTY', 'NIFTY', 'FINNIFTY', 'MIDCPNIFTY']\n",
    "    separated_data = {index: file_paths[file_paths['index_name'] == index].reset_index(drop=True)\n",
    "                      for index in index_names}\n",
    "    \n",
    "    # Accessing the DataFrames\n",
    "    bank_nifty = separated_data['BANKNIFTY']\n",
    "    nifty = separated_data['NIFTY']\n",
    "    fin_nifty = separated_data['FINNIFTY']\n",
    "    mid_nifty = separated_data['MIDCPNIFTY']\n",
    "    index_list = [bank_nifty ,nifty , fin_nifty , mid_nifty ]\n",
    "    weekly_list = {}\n",
    "    next_weekly_list = {}\n",
    "    monthly_list = {}\n",
    "    \n",
    "    for i in index_list :\n",
    "        try:\n",
    "            name = i['index_name'].iloc[0]\n",
    "            weekly  = i['path'][0]\n",
    "            next_weekly = i['path'][1]\n",
    "            monthly = i[(i['expiry'].dt.month == month) & (i['expiry'].dt.year == year)].reset_index(drop = 'First')['path'].iloc[-1]\n",
    "        except Exception as e:\n",
    "            monthly = i[(i['expiry'].dt.month == (month + 1)) & (i['expiry'].dt.year == year)].reset_index(drop = 'First')['path'].iloc[-1]\n",
    "        \n",
    "    exp_name = ['weekly' , 'next_weekly' , 'monthly']\n",
    "    exp_path_list = [weekly_list ,next_weekly_list , monthly_list]\n",
    "    return exp_path_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e9d544-8457-4819-a996-2684ec49e95a",
   "metadata": {},
   "source": [
    "# Find Token Numbers with token details all indexs expirys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56da5c04-f024-4a21-bd3e-380ca3018600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_token_data(exp_path_list):\n",
    "    exp_name = ['weekly' , 'next_weekly' , 'monthly']\n",
    "    for i, path in enumerate(exp_path_list):\n",
    "        print(path)\n",
    "        print(exp_name[i])\n",
    "\n",
    "        # Find Weekly token details (Bank Nifty, Nifty , Fin-Nifty , Mid-Nifty)\n",
    "        if exp_name[i] == 'weekly':\n",
    "            \n",
    "            for key,value in path.items():\n",
    "                \n",
    "                if key == 'BANKNIFTY':\n",
    "                    bank_nifty_token_dic_weekly = pd.read_csv(value , dtype={'Expiry date': object})\n",
    "    \n",
    "                elif key == 'NIFTY':\n",
    "                    nifty_token_dic_weekly = pd.read_csv(value , dtype={'Expiry date': object})\n",
    "                  \n",
    "                elif key == 'FINNIFTY':\n",
    "                    fin_nifty_token_dic_weekly = pd.read_csv(value , dtype={'Expiry date': object})\n",
    "                   \n",
    "                else:\n",
    "                    mid_nifty_token_dic_weekly = pd.read_csv(value , dtype={'Expiry date': object})\n",
    "                    \n",
    "         # Find Next-Weekly token details (Bank Nifty, Nifty , Fin-Nifty , Mid-Nifty)           \n",
    "        elif exp_name[i] == 'next_weekly' :\n",
    "            \n",
    "            for key,value in path.items():\n",
    "                \n",
    "                if key == 'BANKNIFTY':\n",
    "                    bank_nifty_token_dic_next_weekly = pd.read_csv(value , dtype={'Expiry date': object})\n",
    "                    \n",
    "                elif key == 'NIFTY':\n",
    "                    nifty_token_dic_next_weekly = pd.read_csv(value , dtype={'Expiry date': object}) \n",
    "                    \n",
    "                elif key == 'FINNIFTY':\n",
    "                    fin_nifty_token_dic_next_weekly = pd.read_csv(value , dtype={'Expiry date': object})\n",
    "                   \n",
    "                else:\n",
    "                    mid_nifty_token_dic_next_weekly = pd.read_csv(value , dtype={'Expiry date': object})\n",
    "                    \n",
    "         # Find Monthly token details (Bank Nifty, Nifty , Fin-Nifty , Mid-Nifty)\n",
    "        elif exp_name[i] == 'monthly':\n",
    "            for key,value in path.items():\n",
    "                \n",
    "                if key == 'BANKNIFTY':\n",
    "                    bank_nifty_token_dic_monthly = pd.read_csv(value , dtype={'Expiry date': object})\n",
    "                    \n",
    "                elif key == 'NIFTY':\n",
    "                    nifty_token_dic_monthly = pd.read_csv(value , dtype={'Expiry date': object})\n",
    "                   \n",
    "                    \n",
    "                elif key == 'FINNIFTY':\n",
    "                    fin_nifty_token_dic_monthly = pd.read_csv(value , dtype={'Expiry date': object})\n",
    "                   \n",
    "                else:\n",
    "                    mid_nifty_token_dic_monthly = pd.read_csv(value , dtype={'Expiry date': object})\n",
    "\n",
    "    token_dics = {\n",
    "                    'weekly': {'BANKNIFTY': bank_nifty_token_dic_weekly, 'NIFTY': nifty_token_dic_weekly, \n",
    "                               'FINNIFTY': fin_nifty_token_dic_weekly, 'MIDNIFTY': mid_nifty_token_dic_weekly},\n",
    "                    'next_weekly': {'BANKNIFTY': bank_nifty_token_dic_next_weekly, 'NIFTY': nifty_token_dic_next_weekly, \n",
    "                                    'FINNIFTY': fin_nifty_token_dic_next_weekly, 'MIDNIFTY': mid_nifty_token_dic_next_weekly},\n",
    "                    'monthly': {'BANKNIFTY': bank_nifty_token_dic_monthly, 'NIFTY': nifty_token_dic_monthly, \n",
    "                                \n",
    "                                'FINNIFTY': fin_nifty_token_dic_monthly, 'MIDNIFTY': mid_nifty_token_dic_monthly}\n",
    "                }\n",
    "    return token_dics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba83636-d648-4457-ae95-8a8f343b8e19",
   "metadata": {},
   "source": [
    "# Find Future Token Number comman funcation of all indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ed5293-5eed-41b5-962a-c3eac3016c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fut_price_token(today_date_str , index_name):\n",
    "    fut_file = f'Y:\\\\daily_contract_file\\\\{today_date_str}\\\\future_index.csv'\n",
    "    fut_data = pd.read_csv(fut_file)\n",
    "    fut_data['month_exp'] = pd.to_datetime(fut_data['Expiry date'], format='%d%m%Y').dt.month\n",
    "    fut_data = fut_data[fut_data['Symbol'] == index_name]\n",
    "    token_number_fut = fut_data.sort_values(by = 'month_exp',ascending = True).reset_index(drop = 'First').iloc[0]['Token']\n",
    "    return token_number_fut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6433a03-8385-4833-accc-e8e3bdcf966e",
   "metadata": {},
   "source": [
    "# segregate option data of all indexes and all expiry-wise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc4f017-1623-4800-9c24-62804b36ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_path, token_dics, bank_fut_token, nifty_fut_token, fin_nifty_fut_token, mid_nifty_fut_token, chunk_size=100000):\n",
    "    # Initialize your lists\n",
    "    data_dict = {\n",
    "        'weekly_bank_nifty_data': [],\n",
    "        'next_weekly_bank_nifty_data': [],\n",
    "        'monthly_bank_nifty_data': [],\n",
    "        'bank_fut_price': [],\n",
    "        'weekly_nifty_data': [],\n",
    "        'next_weekly_nifty_data': [],\n",
    "        'monthly_nifty_data': [],\n",
    "        'nifty_fut_price': [],\n",
    "        'weekly_fin_nifty_data': [],\n",
    "        'next_weekly_fin_nifty_data': [],\n",
    "        'monthly_fin_nifty_data': [],\n",
    "        'fin_nifty_fut_price': [],\n",
    "        'weekly_mid_nifty_data': [],\n",
    "        'next_weekly_mid_nifty_data': [],\n",
    "        'monthly_mid_nifty_data': [],\n",
    "        'mid_nifty_fut_price': []\n",
    "    }\n",
    "\n",
    "    # Function to clean data\n",
    "    def clean_data(data):\n",
    "        new_name = {\n",
    "            0: 'Token',\n",
    "            2: 'time_entry',\n",
    "            3: 'volume',\n",
    "            4: 'open',\n",
    "            5: 'high',\n",
    "            6: 'low',\n",
    "            7: 'prev-close',\n",
    "            8: 'ltp',\n",
    "            9: 'atp',\n",
    "            13: 'bid_price_1',\n",
    "            15: 'ask_price_1'\n",
    "        }\n",
    "        data.rename(new_name, axis=1, inplace=True)\n",
    "        data['Token'] = data['Token'].str[23:-1]\n",
    "        data['time_entry'] = data['time_entry'].str[16:-1]\n",
    "        data['volume'] = data['volume'].str[11:]\n",
    "        data['open'] = data['open'].str[9:]\n",
    "        data['high'] = data['high'].str[9:]\n",
    "        data['low'] = data['low'].str[8:]\n",
    "        data['prev-close'] = data['prev-close'].str[15:]\n",
    "        data['ltp'] = data['ltp'].str[8:]\n",
    "        data['atp'] = data['atp'].str[8:]\n",
    "        data['bid_price_1'] = data['bid_price_1'].str[16:]\n",
    "        data['ask_price_1'] = data['ask_price_1'].str[16:]\n",
    "        return data\n",
    "\n",
    "    # Function to process chunks and filter data\n",
    "    def process_and_filter_data(data, tokens, category, result_list):\n",
    "        filter_token = [str(i) for i in tokens['Token']]\n",
    "        filtered_chunk = data[data['Token'].isin(filter_token)]\n",
    "        result_list.append(filtered_chunk)\n",
    "\n",
    "    # Read and process data in chunks\n",
    "    for chunk in pd.read_csv(file_path, header=None, chunksize=chunk_size, encoding='utf-8', usecols=[0, 2, 3, 4, 5, 6, 7, 8, 9, 13, 15]):\n",
    "        data = clean_data(chunk)\n",
    "\n",
    "        # Filter future prices\n",
    "        bank_fut_data = data[data['Token'] == str(bank_fut_token)]\n",
    "        data_dict['bank_fut_price'].append(bank_fut_data)\n",
    "\n",
    "        nifty_fut_data = data[data['Token'] == str(nifty_fut_token)]\n",
    "        data_dict['nifty_fut_price'].append(nifty_fut_data)\n",
    "\n",
    "        fin_nifty_fut_data = data[data['Token'] == str(fin_nifty_fut_token)]\n",
    "        data_dict['fin_nifty_fut_price'].append(fin_nifty_fut_data)\n",
    "\n",
    "        mid_nifty_fut_data = data[data['Token'] == str(mid_nifty_fut_token)]\n",
    "        data_dict['mid_nifty_fut_price'].append(mid_nifty_fut_data)\n",
    "\n",
    "        # Process and filter data for each expiration type and index\n",
    "        for expiration, index_tokens in token_dics.items():\n",
    "            for index, tokens in index_tokens.items():\n",
    "                if expiration == 'weekly':\n",
    "                    if index == 'BANKNIFTY':\n",
    "                        process_and_filter_data(data, tokens, 'Token', data_dict['weekly_bank_nifty_data'])\n",
    "                    elif index == 'NIFTY':\n",
    "                        process_and_filter_data(data, tokens, 'Token', data_dict['weekly_nifty_data'])\n",
    "                    elif index == 'FINNIFTY':\n",
    "                        process_and_filter_data(data, tokens, 'Token', data_dict['weekly_fin_nifty_data'])\n",
    "                    else:  # MIDNIFTY\n",
    "                        process_and_filter_data(data, tokens, 'Token', data_dict['weekly_mid_nifty_data'])\n",
    "                elif expiration == 'next_weekly':\n",
    "                    if index == 'BANKNIFTY':\n",
    "                        process_and_filter_data(data, tokens, 'Token', data_dict['next_weekly_bank_nifty_data'])\n",
    "                    elif index == 'NIFTY':\n",
    "                        process_and_filter_data(data, tokens, 'Token', data_dict['next_weekly_nifty_data'])\n",
    "                    elif index == 'FINNIFTY':\n",
    "                        process_and_filter_data(data, tokens, 'Token', data_dict['next_weekly_fin_nifty_data'])\n",
    "                    else:  # MIDNIFTY\n",
    "                        process_and_filter_data(data, tokens, 'Token', data_dict['next_weekly_mid_nifty_data'])\n",
    "                else:  # monthly\n",
    "                    if index == 'BANKNIFTY':\n",
    "                        process_and_filter_data(data, tokens, 'Token', data_dict['monthly_bank_nifty_data'])\n",
    "                    elif index == 'NIFTY':\n",
    "                        process_and_filter_data(data, tokens, 'Token', data_dict['monthly_nifty_data'])\n",
    "                    elif index == 'FINNIFTY':\n",
    "                        process_and_filter_data(data, tokens, 'Token', data_dict['monthly_fin_nifty_data'])\n",
    "                    else:  # MIDNIFTY\n",
    "                        process_and_filter_data(data, tokens, 'Token', data_dict['monthly_mid_nifty_data'])\n",
    "\n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca8b0f1-b605-4782-84d2-3f767e2eb79b",
   "metadata": {},
   "source": [
    "# Merge tokens deatils and future price in option data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d7ec6ce-b350-4484-bb24-e83812daf0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_deatils_merge(data , token_data, fut_data):\n",
    "    # Taken only required columns \n",
    "    token_data = token_data[['Token' , 'strike_price' , 'option_type', 'Expiry date']]\n",
    "\n",
    "    # change token data type int to str\n",
    "    token_data['Token'] = token_data['Token'].astype(str)\n",
    "\n",
    "    # convert expiry date object to datetime type\n",
    "    token_data['Expiry date'] = pd.to_datetime(token_data['Expiry date'] , format = \"%d%m%Y\")\n",
    "\n",
    "    # Merge data\n",
    "    df = pd.merge(data,token_data , on = 'Token' , how=\"inner\")\n",
    "    fut_data = fut_data[['time_entry' , 'ltp']]\n",
    "    fut_data.rename({'ltp': 'future_price'}, axis=1, inplace=True)\n",
    "\n",
    "    \n",
    "    fut_data['time_entry'] = pd.to_datetime(fut_data['time_entry'])\n",
    "    df['time_entry'] = pd.to_datetime(df['time_entry'])\n",
    "    df = df.sort_values(by='time_entry')\n",
    "    # Merge Future price in options data\n",
    "    final_data = pd.merge_asof(df , fut_data , on = 'time_entry' , direction=\"nearest\")\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0ed327-b64f-400d-a82b-8237aec5b404",
   "metadata": {},
   "source": [
    "# Merge Spot price only indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dd9e747-2ac4-4984-aee1-3f0a5c174ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_price_merge(data , index_name , today_date_str):\n",
    "    # Read index data , this is a file path format\n",
    "    index_file = f'Y:\\\\{today_date_str}\\\\index_data.txt'\n",
    "    df= pd.read_csv(index_file , header = None,encoding='utf-8' , usecols=[0,2,3])\n",
    "    df.rename(columns = {0: 'index_name' , 2 : 'time_entry' , 3 : 'spot_price'},inplace = True)\n",
    "    \n",
    "    df['index_name'] = df['index_name'].str[23:-1]\n",
    "    df['time_entry'] = df['time_entry'].str[16:-1]\n",
    "    df['spot_price'] = df['spot_price'].str[8:-2]\n",
    "    \n",
    "    index_data = df[df['index_name'] == index_name].reset_index(drop ='First')\n",
    "    index_data.drop(['index_name'] , axis = 1 ,inplace = True)\n",
    "    index_data['time_entry'] = pd.to_datetime(index_data['time_entry'])\n",
    "    main_data = pd.merge_asof(data , index_data , on='time_entry' , direction=\"nearest\")\n",
    "    main_data['Expiry date'] = pd.to_datetime(main_data['Expiry date'] , format = \"%d%m%Y\")\n",
    "    exp = main_data['Expiry date'].iloc[0].date()\n",
    "    entry_date = main_data['time_entry'].iloc[0].date()\n",
    "    \n",
    "    # Find day to exp (expiry date coulmns minus current date)\n",
    "    main_data['day_to_exp'] = (exp - entry_date).days\n",
    "    return main_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e576c212-2142-4c38-9b1a-5ab047a58f68",
   "metadata": {},
   "source": [
    "# Calculate IV of call with spot price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "087389ee-5126-4716-ad23-efa2b0c34717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_scholes_call(S, X, r, sigma, t):\n",
    "    d1 = (log(S / X) + (r + (sigma ** 2) / 2) * t) / (sigma * sqrt(t))\n",
    "    d2 = d1 - sigma * sqrt(t)\n",
    "    return S * norm.cdf(d1) - X * exp(-r * t) * norm.cdf(d2)\n",
    "def implied_volatility_spot_call(row):\n",
    "    # Extract necessary data from the row\n",
    "    r = 0.01\n",
    "    # Calculate S and X (spot price and strike price)\n",
    "    S = row['spot_price']\n",
    "    X = row['strike_price']\n",
    "    C = row['ltp']\n",
    "    t = row['day_to_exp'] / 365\n",
    "    # If current date is same as expiry date, time to expiry is 0\n",
    "    if t == 0:\n",
    "        t = 0.001  # Avoid division by zero\n",
    "    else:\n",
    "        t = t\n",
    "   \n",
    "    # Define the objective function for implied volatility\n",
    "    def f(sigma):\n",
    "        return black_scholes_call(S, X, r, sigma, t) - C\n",
    "\n",
    "    try:\n",
    "        # Compute implied volatility\n",
    "        implied_volatility = brentq(f, 0.001, 2.0)\n",
    "        return implied_volatility\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ca062a-02a1-440d-9eaf-6f8bd9b40184",
   "metadata": {},
   "source": [
    "# Calculate call IV with Future price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9e8eeef-2b8c-43f2-ae8c-860034f29e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implied_volatility_future_call(row):\n",
    "    # Extract necessary data from the row\n",
    "    r = 0.01\n",
    "    # Calculate S and X (spot price and strike price)\n",
    "    S = row['future_price']\n",
    "    X = row['strike_price']\n",
    "    C = row['ltp']\n",
    "    t = row['day_to_exp'] / 365\n",
    "    # If current date is same as expiry date, time to expiry is 0\n",
    "    if t == 0:\n",
    "        t = 0.001  # Avoid division by zero\n",
    "    else:\n",
    "        t = t\n",
    "    # Define the objective function for implied volatility\n",
    "    def f(sigma):\n",
    "        return black_scholes_call(S, X, r, sigma, t) - C\n",
    "\n",
    "    try:\n",
    "        # Compute implied volatility\n",
    "        implied_volatility = brentq(f, 0.001, 2.0)\n",
    "        return implied_volatility\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2025a7-787a-451e-b9af-a713aca86b26",
   "metadata": {},
   "source": [
    "# Calculate put IV with spot price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd98f380-64eb-4dc5-bf13-4c96210be024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_scholes_put(S, X, r, sigma, t):\n",
    "    d1 = (log(S / X) + (r + (sigma ** 2) / 2) * t) / (sigma * sqrt(t))\n",
    "    d2 = d1 - sigma * sqrt(t)\n",
    "    return X * exp(-r * t) * norm.cdf(-d2) - S * norm.cdf(-d1)\n",
    "def implied_volatility_spot_put(row):\n",
    "    # Extract necessary data from the row\n",
    "    r = 0.01\n",
    "    S = row['spot_price']\n",
    "    X = row['strike_price']\n",
    "    P = row['ltp']\n",
    "    t = row['day_to_exp'] / 365\n",
    "    # If current date is same as expiry date, time to expiry is 0\n",
    "    if t == 0:\n",
    "        t = 0.001  # Avoid division by zero\n",
    "    else:\n",
    "        t = t\n",
    "    # Define the objective function for implied volatility\n",
    "    def f(sigma):\n",
    "        return black_scholes_put(S, X, r, sigma, t) - P\n",
    "\n",
    "    try:\n",
    "        # Compute implied volatility\n",
    "        implied_volatility = brentq(f, 0.001, 2.0)\n",
    "        return implied_volatility\n",
    "    except ValueError:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f456b05-aaad-41a9-92be-9d9e165a08d7",
   "metadata": {},
   "source": [
    "# Calculate put IV with Future price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20e1f662-928d-4c82-967c-8f2f6ea3a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implied_volatility_future_put(row):\n",
    "    # Extract necessary data from the row\n",
    "    r = 0.01\n",
    "    S = row['future_price']\n",
    "    X = row['strike_price']\n",
    "    P = row['ltp']\n",
    "    t = row['day_to_exp'] / 365\n",
    "    # If current date is same as expiry date, time to expiry is 0\n",
    "    if t == 0:\n",
    "        t = 0.001  # Avoid division by zero\n",
    "    else:\n",
    "        t = t\n",
    "   \n",
    "    # Define the objective function for implied volatility\n",
    "    def f(sigma):\n",
    "        return black_scholes_put(S, X, r, sigma, t) - P\n",
    "\n",
    "    try:\n",
    "        # Compute implied volatility\n",
    "        implied_volatility = brentq(f, 0.001, 2.0)\n",
    "        return implied_volatility\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b030823a-53bf-45f3-bf7b-7dae8fd6aa94",
   "metadata": {},
   "source": [
    "# Seprate call data and put data and calculate iv and save data in main data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13c61af4-e1ac-499f-a796-0bf5dfecd4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iv(data):\n",
    "    # change data type str to float\n",
    "    data[['ltp', 'spot_price', 'future_price']] = data[['ltp', 'spot_price', 'future_price']].astype(float)\n",
    "\n",
    "    # Seprate call data and put data\n",
    "    ce_data = data[data['option_type'] == 'CE']\n",
    "    pe_data = data[data['option_type'] == 'PE']\n",
    "\n",
    "    # use funcation for calculate iv seprately spot and future price\n",
    "    ce_data['implied_volatility_spot'] = ce_data.apply(implied_volatility_spot_call, axis=1)\n",
    "    pe_data['implied_volatility_spot'] = pe_data.apply(implied_volatility_spot_put, axis=1)\n",
    "\n",
    "    ce_data['implied_volatility_future'] = ce_data.apply(implied_volatility_future_call, axis=1)\n",
    "    pe_data['implied_volatility_future'] = pe_data.apply(implied_volatility_future_put, axis=1)\n",
    "\n",
    "    # merge call and put data in one dataframe \n",
    "    data = pd.concat([ce_data, pe_data], ignore_index=True).sort_values(by='time_entry')\n",
    "    data['implied_volatility_future'] = data['implied_volatility_future']*100\n",
    "    data['implied_volatility_spot'] = data['implied_volatility_spot']*100\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f028bfaf-1366-4574-b011-a498104bab6f",
   "metadata": {},
   "source": [
    "# Save data in mongodb database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb2f7b44-4441-45d9-8b95-8648eb65d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mongodb_save(data,today_date_str,data_base_name , collection_name):\n",
    "    # Create database name\n",
    "    database_name = f'{data_base_name}_option_data_{today_date_str}'\n",
    "    client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "    db = client[database_name]\n",
    "    coll = db[collection_name]\n",
    "    dt = data.to_dict(orient='records')\n",
    "    coll.insert_many(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb75d68d-21a7-4cbf-9ccb-87d1438be66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    today_date = datetime.today().date()\n",
    "    today_date_str = today_date.strftime(\"%d%m%Y\")\n",
    "    #today_date_str = '31052024'\n",
    "    option_path = f'Y:\\\\{today_date_str}\\\\option_data.txt'\n",
    "\n",
    "    # Find expiry wise token file path all expiry (bank-nifty , nifty , fin-nifty ,mid-nify)\n",
    "    exp_path_list = find_expiry_path(today_date_str = today_date_str)\n",
    "\n",
    "    # Find expiry wise token dataframe expiry (bank-nifty , nifty , fin-nifty , mid-nifty)\n",
    "    token_dics = find_token_data(exp_path_list =exp_path_list)\n",
    "\n",
    "    # Find Future tokens (bank-nifty , nifty , fin-nifty, mid-nifty)\n",
    "    bank_fut_token = fut_price_token(today_date_str = today_date_str , index_name = 'BANKNIFTY')\n",
    "    nifty_fut_token = fut_price_token(today_date_str = today_date_str , index_name = 'NIFTY')\n",
    "    fin_nifty_fut_token = fut_price_token(today_date_str = today_date_str , index_name = 'FINNIFTY')\n",
    "    mid_nifty_fut_token = fut_price_token(today_date_str = today_date_str , index_name = 'MIDCPNIFTY')\n",
    "\n",
    "    # This is a funcation to find options data \n",
    "    data_dict = process_data(file_path = option_path , token_dics =token_dics , bank_fut_token =bank_fut_token , nifty_fut_token = nifty_fut_token\n",
    "                 , fin_nifty_fut_token = fin_nifty_fut_token , mid_nifty_fut_token =mid_nifty_fut_token , chunk_size=100000)\n",
    "\n",
    "    # This is a bank-nifty option data (weekly , next-weekly , monthly and future data)\n",
    "    weekly_bank_nifty_data = pd.concat(data_dict['weekly_bank_nifty_data']).reset_index(drop = 'First')\n",
    "    next_weekly_bank_nifty_data = pd.concat(data_dict['next_weekly_bank_nifty_data']).reset_index(drop = 'First')\n",
    "    monthly_bank_nifty_data = pd.concat(data_dict['monthly_bank_nifty_data']).reset_index(drop = 'First')\n",
    "    bank_fut_price = pd.concat(data_dict['bank_fut_price']).reset_index(drop = 'First')\n",
    "\n",
    "     # This is a nifty option data (weekly , next-weekly , monthly and future data)\n",
    "    weekly_nifty_data = pd.concat(data_dict['weekly_nifty_data']).reset_index(drop = 'First')\n",
    "    next_weekly_nifty_data = pd.concat(data_dict['next_weekly_nifty_data']).reset_index(drop = 'First')\n",
    "    monthly_nifty_data = pd.concat(data_dict['monthly_nifty_data']).reset_index(drop = 'First')\n",
    "    nifty_fut_price = pd.concat(data_dict['nifty_fut_price']).reset_index(drop = 'First')\n",
    "    \n",
    "    # This is a fin-nifty option data (weekly , next-weekly , monthly and future data)\n",
    "    weekly_fin_nifty_data = pd.concat(data_dict['weekly_fin_nifty_data']).reset_index(drop = 'First')\n",
    "    next_weekly_fin_nifty_data = pd.concat(data_dict['next_weekly_fin_nifty_data']).reset_index(drop = 'First')\n",
    "    monthly_fin_nifty_data = pd.concat(data_dict['monthly_fin_nifty_data']).reset_index(drop = 'First')\n",
    "    fin_nifty_fut_price = pd.concat(data_dict['fin_nifty_fut_price']).reset_index(drop = 'First')\n",
    "\n",
    "    # This is a mid-nifty option data (weekly , next-weekly , monthly and future data)\n",
    "    weekly_mid_nifty_data = pd.concat(data_dict['weekly_mid_nifty_data']).reset_index(drop = 'First')\n",
    "    next_weekly_mid_nifty_data = pd.concat(data_dict['next_weekly_mid_nifty_data']).reset_index(drop = 'First')\n",
    "    monthly_mid_nifty_data = pd.concat(data_dict['monthly_mid_nifty_data']).reset_index(drop = 'First')\n",
    "    mid_nifty_fut_price = pd.concat(data_dict['mid_nifty_fut_price']).reset_index(drop = 'First')\n",
    "\n",
    "    # Find bank-nifty token details weekly and next weekly and monthly\n",
    "    bank_nifty_token_dic_weekly = token_dics['weekly']['BANKNIFTY']\n",
    "    bank_nifty_token_dic_next_weekly = token_dics['next_weekly']['BANKNIFTY']\n",
    "    bank_nifty_token_dic_monthly = token_dics['monthly']['BANKNIFTY']\n",
    "\n",
    "    # Find nifty token details weekly and next weekly and monthly\n",
    "    nifty_token_dic_weekly = token_dics['weekly']['NIFTY']\n",
    "    nifty_token_dic_next_weekly = token_dics['next_weekly']['NIFTY']\n",
    "    nifty_token_dic_monthly = token_dics['monthly']['NIFTY']\n",
    "\n",
    "    # Find fin-nifty token details weekly and next weekly and monthly\n",
    "    fin_nifty_token_dic_weekly = token_dics['weekly']['FINNIFTY']\n",
    "    fin_nifty_token_dic_next_weekly = token_dics['next_weekly']['FINNIFTY']\n",
    "    fin_nifty_token_dic_monthly = token_dics['monthly']['FINNIFTY']\n",
    "\n",
    "    # Find mid-nifty token details weekly and next weekly and monthly\n",
    "    mid_nifty_token_dic_weekly = token_dics['weekly']['MIDNIFTY']\n",
    "    mid_nifty_token_dic_next_weekly = token_dics['next_weekly']['MIDNIFTY']\n",
    "    mid_nifty_token_dic_monthly = token_dics['monthly']['MIDNIFTY']\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Merge Token details bank nifty weekly and next weekly and monthly (strike price , option type expiry and Future price)\n",
    "    bank_data_weekly = token_deatils_merge(data = weekly_bank_nifty_data ,token_data = bank_nifty_token_dic_weekly ,fut_data =  bank_fut_price )\n",
    "    bank_data_next_weekly = token_deatils_merge(data = next_weekly_bank_nifty_data ,token_data = bank_nifty_token_dic_next_weekly ,fut_data =  bank_fut_price )\n",
    "    bank_data_monthly = token_deatils_merge(data = monthly_bank_nifty_data , token_data = bank_nifty_token_dic_monthly , fut_data =  bank_fut_price )\n",
    "\n",
    "    # Merge Token deatils nifty weekly and next weekly and monthly (strike price , option type expiry and Future price)\n",
    "    nifty_data_weekly = token_deatils_merge(data = weekly_nifty_data ,token_data = nifty_token_dic_weekly ,fut_data =  nifty_fut_price )\n",
    "    nifty_data_next_weekly = token_deatils_merge(data = next_weekly_nifty_data ,token_data = nifty_token_dic_next_weekly ,fut_data =  nifty_fut_price )\n",
    "    nifty_data_monthly = token_deatils_merge(data = monthly_nifty_data ,token_data = nifty_token_dic_monthly ,fut_data =  nifty_fut_price )\n",
    "\n",
    "    # Merge Token deatils Fin-nifty weekly and next weekly and monthly (strike price , option type expiry and Future price)\n",
    "    fin_nifty_weekly = token_deatils_merge(data = weekly_fin_nifty_data ,token_data = fin_nifty_token_dic_weekly ,fut_data =  fin_nifty_fut_price )\n",
    "    fin_nifty_next_weekly = token_deatils_merge(data = next_weekly_fin_nifty_data ,token_data = fin_nifty_token_dic_next_weekly ,fut_data =  fin_nifty_fut_price )\n",
    "    fin_nifty_monthly = token_deatils_merge(data = monthly_fin_nifty_data ,token_data = fin_nifty_token_dic_monthly ,fut_data =  fin_nifty_fut_price )\n",
    "\n",
    "    # Merge Token deatils mid-nifty weekly and next weekly and monthly (strike price , option type expiry and Future price)\n",
    "    mid_nifty_weekly = token_deatils_merge(data = weekly_mid_nifty_data ,token_data = mid_nifty_token_dic_weekly ,fut_data =  mid_nifty_fut_price )\n",
    "    mid_nifty_next_weekly = token_deatils_merge(data = next_weekly_mid_nifty_data ,token_data = mid_nifty_token_dic_next_weekly ,fut_data =  mid_nifty_fut_price )\n",
    "    mid_nifty_monthly = token_deatils_merge(data = monthly_mid_nifty_data ,token_data = mid_nifty_token_dic_monthly ,fut_data =  mid_nifty_fut_price )\n",
    "\n",
    "    # add spot price in datas\n",
    "\n",
    "    # Bank nifty weekly and next weekly and monthly\n",
    "    main_data_bank_weekly  = spot_price_merge(data =bank_data_weekly , index_name = 'NiftyBank' , today_date_str = today_date_str)\n",
    "    main_data_bank_next_weekly  = spot_price_merge(data =bank_data_next_weekly , index_name = 'NiftyBank' , today_date_str = today_date_str)\n",
    "    main_data_bank_monthly = spot_price_merge(data =bank_data_monthly , index_name = 'NiftyBank' , today_date_str = today_date_str)\n",
    "\n",
    "    # Nifty weekly and next weekly and monthly\n",
    "    main_data_nifty_weekly = spot_price_merge(data =nifty_data_weekly , index_name = 'Nifty50' , today_date_str = today_date_str)\n",
    "    main_data_nifty_next_weekly = spot_price_merge(data =nifty_data_next_weekly , index_name = 'Nifty50' , today_date_str = today_date_str)\n",
    "    main_data_nifty_monthly = spot_price_merge(data =nifty_data_monthly , index_name = 'Nifty50' , today_date_str = today_date_str)\n",
    "\n",
    "    # Fin-nifty weekly and next weekly and monthly\n",
    "    main_data_fin_nifty_weekly = spot_price_merge(data =fin_nifty_weekly , index_name = 'NiftyFinService' , today_date_str = today_date_str)\n",
    "    main_data_fin_nifty_next_weekly = spot_price_merge(data =fin_nifty_next_weekly , index_name = 'NiftyFinService' , today_date_str = today_date_str)\n",
    "    main_data_fin_nifty_monthly = spot_price_merge(data =fin_nifty_monthly , index_name = 'NiftyFinService' , today_date_str = today_date_str)\n",
    "\n",
    "    # Mid-nifty weekly and next weekly and monthly \n",
    "    main_data_mid_nifty_weekly = spot_price_merge(data =mid_nifty_weekly , index_name = 'NIFTYMIDSELECT' , today_date_str = today_date_str)\n",
    "    main_data_mid_nifty_next_weekly = spot_price_merge(data =mid_nifty_next_weekly , index_name = 'NIFTYMIDSELECT' , today_date_str = today_date_str)\n",
    "    main_data_mid_nifty_monthly = spot_price_merge(data =mid_nifty_monthly , index_name = 'NIFTYMIDSELECT' , today_date_str = today_date_str)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    # Find Bank-Nifty IV \n",
    "    main_data_bank_weekly = calculate_iv(data = main_data_bank_weekly)\n",
    "    main_data_bank_next_weekly = calculate_iv(data = main_data_bank_next_weekly)\n",
    "    main_data_bank_monthly = calculate_iv(data = main_data_bank_monthly)\n",
    "\n",
    "    # Find Nifty IV\n",
    "    main_data_nifty_weekly = calculate_iv(data = main_data_nifty_weekly)\n",
    "    main_data_nifty_next_weekly = calculate_iv(data = main_data_nifty_next_weekly)\n",
    "    main_data_nifty_monthly = calculate_iv(data = main_data_nifty_monthly)\n",
    "\n",
    "    # Find Fin-Nifty IV\n",
    "    main_data_fin_nifty_weekly = calculate_iv(data = main_data_fin_nifty_weekly)\n",
    "    main_data_fin_nifty_next_weekly = calculate_iv(data = main_data_fin_nifty_next_weekly)\n",
    "    main_data_fin_nifty_monthly = calculate_iv(data = main_data_fin_nifty_monthly)\n",
    "\n",
    "    # Find Mid-Nifty IV\n",
    "    main_data_mid_nifty_weekly = calculate_iv(data = main_data_mid_nifty_weekly)\n",
    "    main_data_mid_nifty_next_weekly = calculate_iv(data = main_data_mid_nifty_next_weekly)\n",
    "    main_data_mid_nifty_monthly = calculate_iv(data = main_data_mid_nifty_monthly)\n",
    "    \n",
    "    # Bank nifty data save in mongodb (weekly , next-weekly,monthly)\n",
    "    mongodb_save(data = main_data_bank_weekly , today_date_str = today_date_str , data_base_name = 'banknifty' , collection_name = 'weekly')\n",
    "    mongodb_save(data = main_data_bank_next_weekly , today_date_str = today_date_str , data_base_name = 'banknifty' , collection_name = 'next_weekly')\n",
    "    mongodb_save(data = main_data_bank_monthly , today_date_str = today_date_str , data_base_name = 'banknifty' , collection_name = 'monthly')\n",
    "\n",
    "    # Nifty data save in mongodb (weekly , next-weekly,monthly)\n",
    "    mongodb_save(data = main_data_nifty_weekly , today_date_str = today_date_str , data_base_name = 'nifty' , collection_name = 'weekly')\n",
    "    mongodb_save(data = main_data_nifty_next_weekly , today_date_str = today_date_str , data_base_name = 'nifty' , collection_name = 'next_weekly')\n",
    "    mongodb_save(data = main_data_nifty_monthly , today_date_str = today_date_str , data_base_name = 'nifty' , collection_name = 'monthly')\n",
    "\n",
    "    # Fin-Nifty data save in mongodb (weekly , next-weekly,monthly)\n",
    "    mongodb_save(data = main_data_fin_nifty_weekly , today_date_str = today_date_str , data_base_name = 'fin-nifty' , collection_name = 'weekly')\n",
    "    mongodb_save(data = main_data_fin_nifty_next_weekly , today_date_str = today_date_str , data_base_name = 'fin-nifty' , collection_name = 'next_weekly')\n",
    "    mongodb_save(data = main_data_fin_nifty_monthly, today_date_str = today_date_str , data_base_name = 'fin-nifty' , collection_name = 'monthly')\n",
    "\n",
    "    # Mid-Nifty data save in mongodb (weekly , next-weekly,monthly)\n",
    "    mongodb_save(data = main_data_mid_nifty_weekly , today_date_str = today_date_str , data_base_name = 'mid-nifty' , collection_name = 'weekly')\n",
    "    mongodb_save(data = main_data_mid_nifty_next_weekly , today_date_str = today_date_str , data_base_name = 'mid-nifty' , collection_name = 'next_weekly')\n",
    "    mongodb_save(data = main_data_mid_nifty_monthly , today_date_str = today_date_str , data_base_name = 'mid-nifty' , collection_name = 'monthly')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcd48772-9a50-4deb-945d-cdbb41b5eae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BANKNIFTY': 'Y:\\\\daily_contract_file\\\\03062024\\\\BANKNIFTY_05062024.csv', 'NIFTY': 'Y:\\\\daily_contract_file\\\\03062024\\\\NIFTY_06062024.csv', 'FINNIFTY': 'Y:\\\\daily_contract_file\\\\03062024\\\\FINNIFTY_04062024.csv', 'MIDCPNIFTY': 'Y:\\\\daily_contract_file\\\\03062024\\\\MIDCPNIFTY_03062024.csv'}\n",
      "weekly\n",
      "{'BANKNIFTY': 'Y:\\\\daily_contract_file\\\\03062024\\\\BANKNIFTY_12062024.csv', 'NIFTY': 'Y:\\\\daily_contract_file\\\\03062024\\\\NIFTY_13062024.csv', 'FINNIFTY': 'Y:\\\\daily_contract_file\\\\03062024\\\\FINNIFTY_11062024.csv', 'MIDCPNIFTY': 'Y:\\\\daily_contract_file\\\\03062024\\\\MIDCPNIFTY_10062024.csv'}\n",
      "next_weekly\n",
      "{'BANKNIFTY': 'Y:\\\\daily_contract_file\\\\03062024\\\\BANKNIFTY_26062024.csv', 'NIFTY': 'Y:\\\\daily_contract_file\\\\03062024\\\\NIFTY_29062028.csv', 'FINNIFTY': 'Y:\\\\daily_contract_file\\\\03062024\\\\FINNIFTY_25062024.csv', 'MIDCPNIFTY': 'Y:\\\\daily_contract_file\\\\03062024\\\\MIDCPNIFTY_24062024.csv'}\n",
      "monthly\n",
      "Elapsed time: 98.33 seconds\n",
      "Elapsed time: 10618.11 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e261300-96d0-4b29-95a2-96f57bc0137d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d028c82-a7f2-474a-b1e5-fd235af74a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e6cef4-4f18-435a-a2be-f65d40aa5fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a432db0b-546c-4a4e-8583-b1cbe01715f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dff8f2-6137-4068-a457-d4e7ad876d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67b9b8b-3a43-4d0a-b656-d683f9ad7597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62cf6bb-e585-4587-a124-2d51ef6e7174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc836b6b-4172-4369-84a2-f279f427395f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e87810-eb5d-441b-90a0-bc0a1a2be301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d356b-e7c1-42da-88ec-5d408eca5aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcc89fb-7c4e-4516-9b16-76efd14abb36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a322c56b-3e3b-4304-8e5b-8734c428e489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5fa983-d64e-49ed-9ab9-ae5fae9f36d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de09a2-71cb-40b2-9f72-42091227d226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf30bc8-bcde-4a32-b476-7a25e5e9dec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abab715-6e95-4086-8442-c0994f8710a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0514532-aae5-4685-a33f-2a3c0006020d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22294cbb-80e6-498f-8e5f-d887c3fab761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6acb2-910d-4fa5-8c50-8992da18074a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab195efe-e09e-4990-a8d2-f9a0c585932f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988ce62-1f7a-4720-8c65-2730bd5fffd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c9c19b-4d0a-4758-9074-c9481419c6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb9b68a-b8cb-47ae-8362-0548cc9fee38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4529e3f5-899d-4f70-8f2c-3e0cbb3c9d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca18404d-3cdf-41dc-b57d-468ebcc91194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b496c22-abe3-4ec9-9aa6-eaac9d36f121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ebeea2-3fb0-459e-bcc4-400ecfaa8415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c898a17-dad5-4980-8780-92f597dbc3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
